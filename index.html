<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <title>Automatic Life</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>
    * {
      box-sizing: border-box;
      font-family: 'Segoe UI', system-ui, sans-serif;
    }

    body {
      margin: 0;
      height: 100vh;
      background: radial-gradient(circle at bottom, #020024, #000010, #000);
      overflow: hidden;
      display: flex;
      align-items: center;
      justify-content: center;
      color: white;
    }

    /* Fondo espacial animado */
    body::before {
      content: "";
      position: absolute;
      inset: 0;
      background:
        url("https://raw.githubusercontent.com/JulianLaval/canvas-particle-network/master/img/stars.png") repeat;
      animation: moveStars 120s linear infinite;
      opacity: 0.5;
      z-index: 0;
    }

    @keyframes moveStars {
      from { background-position: 0 0; }
      to { background-position: -2000px 2000px; }
    }

    .app {
      position: relative;
      z-index: 1;
      text-align: center;
      padding: 2.5rem 3rem;
      border-radius: 24px;
      background: rgba(10, 10, 30, 0.6);
      backdrop-filter: blur(16px);
      box-shadow: 0 0 40px rgba(0, 255, 255, 0.2);
    }

    h1 {
      margin-bottom: 2rem;
      font-size: 2.4rem;
      letter-spacing: 2px;
      text-shadow: 0 0 12px #00ffff;
    }

    #startBtn {
      padding: 1.1rem 3.2rem;
      font-size: 1.3rem;
      border-radius: 999px;
      border: none;
      cursor: pointer;
      background: linear-gradient(135deg, #00ffff, #7f00ff);
      color: black;
      font-weight: 700;
      letter-spacing: 1px;
      box-shadow:
        0 0 15px #00ffff,
        0 0 40px rgba(127, 0, 255, 0.6);
      transition: all 0.25s ease;
    }

    #startBtn:hover {
      transform: scale(1.08);
      box-shadow:
        0 0 25px #00ffff,
        0 0 60px rgba(127, 0, 255, 0.9);
    }

    #startBtn:active {
      transform: scale(0.95);
    }

    .output {
      margin-top: 2rem;
      font-size: 1.05rem;
      opacity: 0.9;
    }

    #transcribedText {
      display: block;
      margin-top: 0.7rem;
      font-size: 1.1rem;
      color: #00ffff;
      text-shadow: 0 0 6px #00ffff;
      min-height: 1.4em;
    }
  </style>
</head>

<body>
  <div class="app">
    <h1>Automatic Life</h1>
    <button id="startBtn">Grabar</button>
    <div class="output">
      Texto:
      <span id="transcribedText"></span>
    </div>
  </div>

  <script>
    let mediaRecorder;
    let audioChunks = [];

    const startBtn = document.getElementById("startBtn");
    const transcribedText = document.getElementById("transcribedText");

    startBtn.onclick = async () => {
      if (!mediaRecorder || mediaRecorder.state === "inactive") {
        // Obtener audio del micrófono
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];

        mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
        mediaRecorder.onstop = sendAudio;
        mediaRecorder.start();
        startBtn.textContent = "Detener";
        console.log("Grabando audio...");
      } else {
        mediaRecorder.stop();
        startBtn.textContent = "Grabar";
        console.log("Audio detenido, enviando...");
      }
    };

    async function sendAudio() {
      const blob = new Blob(audioChunks, { type: "audio/webm" });
      const reader = new FileReader();
      reader.readAsDataURL(blob);

      reader.onloadend = async () => {
        const base64 = reader.result.split(",")[1];
        console.log("Audio base64:", base64);

        try {
          // 1️⃣ Transcribir audio
          const resTrans = await fetch("/.netlify/functions/transcribe", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: base64
          });

          const dataTrans = await resTrans.json();
          console.log("Respuesta transcribe:", dataTrans);

          const texto = dataTrans.text || "[Error de transcripción]";
          transcribedText.textContent = texto;

          // 2️⃣ Enviar a respond.js para TTS y guardado en Google Sheets
          const resResp = await fetch("/.netlify/functions/respond", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text: texto })
          });

          const dataResp = await resResp.json();
          console.log("Respuesta respond:", dataResp);

          if (dataResp.ok && dataResp.audioBase64) {
            const audio = new Audio(`data:audio/mpeg;base64,${dataResp.audioBase64}`);
            audio.play();
          }
        } catch (err) {
          console.error("Error en la transcripción o respuesta:", err);
          transcribedText.textContent = "[Error de transcripción]";
        }
      };
    }
  </script>
</body>
</html>
